\documentclass[11pt]{article}

\usepackage{fullpage}
\usepackage[round,semicolon]{natbib}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{bbm}
\usepackage{booktabs}
\usepackage[font=footnotesize,labelfont=bf]{caption}
\usepackage{colortbl}
\usepackage{fixltx2e}
\usepackage{float}
\usepackage{graphicx}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{natbib}
\usepackage{standalone}
\usepackage[normalem]{ulem}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}

\usepackage{indentfirst}
\newcommand{\pr}{\text{Pr}}

\newcommand{\ETAL}{\textit{et al.}}
\newcommand{\EG}{\textit{e.g.}}
\newcommand{\IE}{\textit{i.e.}}
\newcommand{\CF}{\textit{c.f.}}

\usepackage{hyperref}

% NOTE: one sentence per line for nice git diffs
% WD: I'm a fan of source comments like this, instead of the colory ones in the pdf. But Ok fine, have it your way!
\usepackage{color}
% Will comments
\newcommand{\wdcomment}[1]{{\color{magenta}{(\textbf{WD's comment:} #1)}}}
% Andy comments
\newcommand{\amcomment}[1]{{\color{blue}{(\textbf{AM's comment:} #1)}}}
% Sarah comments
\newcommand{\skhcomment}[1]{{\color{red}{(\textbf{SH's comment:} #1)}}}


\title{Phyload: a story of paired sites finding their way in an unpaired model space}

% WD: this alphabetical author list is copied from the previous version, not meant to indicate priority
\author{
William DeWitt$^{1\ast}$, Sarah Hilton$^{1\ast}$, and Andrew Magee$^{2\ast}$\\
\small{Departments of $^1$Genome Sciences and $^2$Biology, University of Washington, Seattle, USA}\\
\small{$^\ast$ Equal contribution}
}
% \author[1]{Sarah Hilton}
% \author[2]{Andy Magee}

% \affil[1]{Department of Genome Sciences, University of Washington, Seattle, USA}
% \affil[2]{Department of Biology, University of Washington, Seattle, USA}

\begin{document}

\maketitle

\begin{abstract}
Phylogenetic inference relies on probabilistic models of character state change along tree branches in which sites in the alignment are statistically independent.
This severely restrictive assumption facilitates computational tractability, but ignores the influence that epistasis, or the effect of genetic background on mutational effects, has on the evolution of functional sequences.
We consider the effect of using a misspecified site-independent model on the accuracy of phylogenetic inference in the setting of pairwise-site epistasis.
We show that including epistatically coupled sites in an alignment improves reconstruction accuracy and we introduce an alignment test statistic that is diagnostic for epistasis and can be used in posterior predictive checks.
\end{abstract}

\section*{{Introduction}\label{sec:intro}}

Epistasis is the phenomenon where the effect of a mutation at one site in a sequence is dependent on the identity of another site or sites.
This dependence is pervasive in datasets for phylogenetic inference and can manifests itself as interactions between different genes $<cite>$, between different sites in a protein $<cite>$, or between different sites in RNA $<cite>$
In the specific case of RNA, stem and loop secondary structures are evolutionary conserved by paired substitutions at specific sites to maintain Watson-Crick pairing (A-T and G-C).

\amcomment{It is probably worth pointing out that our focusing in on RNA is actually quite pragmatic, as there is a well-developed literature on this sort of epistasis.}

In contrast, the vast majority phylogenetic models rely on the assumption that sites in the alignment are statistically independent.
Relaxing this assumption requires two new pieces of information: a method to identify the dependent sites and a model to character state change in the dependent regime.
While there is work on models with large alphabets (nucleotides or amino acids) and high-order epistasis $<cite$ nicolas rodrigue among others$>$, here we restrict our consideration to the simple case of pairwise dependence of sites in an RNA.
Phylogenetic models of epistasis have a long history... we should be sure to emphasize here that most of these are pair models.
$<$We need to talk up the NH model here a decent bit$>$
\amcomment{We also need to be clear if we're going to discuss it as a model that has both iid and interacting sites or not, so we can be clear about our terminology when we set up our grid}
% SHHere we should spend some time talking about protein models as well. Nicolas Rodrigue has a few. But they are so complicated and will probably take forever to run. I think he even has a paper that is like this is not worth it.}

However, phylogenetic models of epistasis are not without drawbacks.
To apply a model that incorporates dependence between sites, one must either specify \textit{a priori} which sites are dependent, or the model must be capable of inferring these pairings.
Defining pairings before analysis requires either that such information is available in a database \citep[\textit{e.g.},][]{wuyts2004european}, or that one can infer the secondary structure \citep[\textit{e.g.},][]{lorenz2011viennarna}.
If such information is not available, secondary structure prediction proves problematic, then to avoid conditioning on pairs, one must integrate over pairings in some way.
\cite{meyer2019simultaneous} employ reversible-jump MCMC \citep{green1995reversible} to sample possible pairings, which drastically increases the statespace of the model.
One can also calculate the likelihood for all possible site pairings, as in \citet{golden2020evolutionary}, but as the number of pairings for $n$ sites is $n \choose 2$, this drastically increases the computational burden of calculating the likelihood of the data.
Whether the integration is accomplished via MCMC or analytically, it is costly.
Regardless of whether pairing is inferred or specified, current models assume that the pairs of interacting sites are fixed over the history of the tree.
The effects of this assumption are unknown, but the state-space required to accommodate changes in pairings over time, in addition to inferring them, likely precludes the development of models that include this feature.

Beyond the challenges of identifying pairs of interacting sites, the models for epistatically paired sites can be computationally burdensome.
In the simple case of pairwise epistasis on the nucleotide level the size of the rate matrix grows from from $4 \times 4$ to $16 \times 16$.
While models like that of \citet{nasrallah2013phylogenetic} avoid a large increase in the number of parameters by defining this matrix in relationship to an underlying nucleotide GTR model, the number of parameters required to model an rRNA sequence still increases from 9 to 25 to account for pairwise epistasis.
In other models, additional, potentially high-dimensional, parameters are required.
To model co-evolution in cases where the interacting sets are not known \textit{a priori}, the model of \citet{meyer2019simultaneous} must infer the so-called ``profile'' of coevolution for each pair of interacting sites, a discrete parameter with 192 possible values.
To incorporate more of the evolutionary forces in an rRNA alignment, the model of \citet{golden2020evolutionary}



In parallel to literature on phylogenetic models of epistasis is literature on detecting epistasis in phylogenetic datasets.
$<$Citations and some literature reviewing$>$
This literature has mostly been confined to detecting the presence of epistatic interactions in datasets, and decoupled from either modeling these interactions or asking whether they distort inferred phylogenies.
$<$Mumble mumble they should have been doing posterior-predictive testing, or at least using alignment-based summary statistics because those are better because reasons.$>$

Given the difficulties involved in applying epistatic phylogenetic models to real datasets, we seek to answer two questions involving the use of misspecified site-iid models for data generated from a evolutionary process with (pairwise) epistasis.
Can we \textit{detect} detect the presence of unmodeled (pairwise) epistasis in datasets using posterior-predictive model checks?
What is the \textit{effect} of including epistatically paired sites on the quality of inferred trees?
To address these questions, we perform a simulation study using the pairwise epistatic model of \cite{nasrallah2013phylogenetic}.
We simulate alignments on a 3-dimensional parameter grid, defined by the number of sites in the alignment that are site-iid $n_{\mathrm{i}}$, the number of sites that are epistatically paired $n_{\mathrm{e}}$, and the strength of epistatic interactions $d$.
Our grid thus includes a range of alignment sizes $n = n_{\mathrm{i}}+n_{\mathrm{e}}$, a range of epistatic fractions $\frac{n_{\mathrm{e}}}{n_{\mathrm{i}}+n_{\mathrm{e}}}$ for each size.
We assess several alignment test statistics---some previously described and several new ones designed to detect epistasis specifically---for their ability to detect epistasis directly from alignments using posterior predictive checks, answering our first question.
The use of a variable alignment length allows us to answer our second question and determine whether the inclusion of epistatic sites in an alignment improves or worsens phylogenetic estimates.
Specifically, we examine whether adding $n_e$ epistatic sites to an alignment of size $n$ makes the inference better or worse.
By synthesizing the results from answering the first two questions, we can address whether we can detect (pairwise) epistasis when it is making inference noticeably worse, answering our third question.
% WD this statement needs more rigour, if possible

\section*{Methods\label{sec:methods}}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{figures/schematic.png}
  \caption{
a) Tunicate tree, iid model and epi model fit to tunicates. b) simulate alignments under the models in (a). These simulated alignments vary in their lengths, proportion of epistatic sites, and strength of the epistatic interactions. c) MCMC on the simulated alignments. d) simulate alignments from the posterior of (c). e) posterior predictive check using either the G93 metric, MI max or MI skewness. f) RF distance between true tree and inferred tree.
  }
  \label{fig:schematic}
\end{figure}

\subsection*{Model\label{sec:model}}

\amcomment{We should change this around in an order we like and with notation we like.}

For all our simulations, we employ the epistatic RNA doublet model of \cite{nasrallah2013phylogenetic}, which we implemented in RevBayes \citep{hohna2016revbayes}.
In this model, there are two categories of sites: paired sites experiencing epistatic interactions (which we will refer to as epistatic sites) and unpaired sites evolving independently (which we will refer to as independent sites).
Within each category, it is assumed that all sites (or site pairs) evolve under the same model.
The independent sites evolve under a standard GTR+G substitution model \citep{tavare1986some}.
The epistatic sites evolve under a generalization of the RNA doublet model of \cite{schoniger1994stochastic} with gamma-distributed rate heterogeneity.
The (symmetric) nucleotide exchange rates and the shape parameter of the gamma-distributed rate heterogeneity are shared between the models for the independent and epistatic sites.
We now describe the model for epistatic sites.

Let $\boldsymbol{Q}$ be the instantaneous rate matrix describing changes from doublet $\boldsymbol{x}$ to doublet $y$.
For $\boldsymbol{x} = (x_1, x_2)$, $x_1$ is the 5' nucleotide and $x_2$ is the 3' nucleotide.
The rate matrix is defined as,
\begin{equation}
\label{eq:Q}
\boldsymbol{Q} = \xi \times
\begin{cases}
   \pi_{y} S_{x_1, y_1} & \mbox{if single substitution at the 5' site,} \\
   \pi_{y} S_{x_2, y_2} & \mbox{if single substitution at the 3' site,} \\
   \pi_{y} S_{x_1, y_1} S_{x_2, y_2} d & \mbox{if double substitution where ${\boldsymbol{x}}$ and ${y}$ $\in {\boldsymbol{W}}$,} \\
   0 & \mbox{if any other double substitution,} \\
   - \sum_{\boldsymbol{x} \ne y} Q_{\boldsymbol{x},y}& \mbox{if $\boldsymbol{x}$ = $y$} \\
   \end{cases}
\end{equation}
where $\boldsymbol{S}$ is the GTR exchangeability matrix (shared with the independent sites) and $S_{x_i,y_i}$ is understood to be the element in $S$ governing the rate of exchangeability between nucleotide $x_i$ and $y_i$ (by definition, $S_{x_i,y_i} = S_{y_i,x_i}$),
${\boldsymbol{W}} = (AT, CG, GC, TA)$ is the set of Watson-Crick pairs,
$\boldsymbol{\pi} = (\pi_{AA}, \pi_{AC}, ..., \pi_{TT})$ are the stationary state frequencies of the 16 possible doublet states,
$d$ controls rate of double to single mutations between doublets,
and $\xi$ is the rate-scaling factor (the matrix is normalized to one substitution per single site for comparability with the independent sites).

The parameter $d$ controls the strength of epistatic interactions.
At $d = 0$, there are no double substitutions and this model collapses to the model of \cite{schoniger1994stochastic}.
When $d = \infty$, all substitutions are double substitutions.
In the intervening regimes, a portion of substitutions at epistatically paired sites will be doublet substitutions while the remainder will be single-site changes.
We can compute the total fraction of the substitutions that are doublet substitutions as,
\[
p = \frac{ d \times r_{d} }{d \times r_{d} + r_{s}}
\]
with $r_d$ being $1 / d$ times the total rate of doublet subtitutions,
\[
  r_{d} = \sum_{x,y \in \boldsymbol{W}} \pi_{xy} \pi_{yx} S_{x_1,y_1} S_{x_2,y_2},
\]
and $r_s$ being the total rate of single substitutions,
\[
  r_{s} = \sum_{x,y \not\in \boldsymbol{W}} \pi_{xy} \pi_{yx} S_{x_1,y_1} S_{x_2,y_2}.
\]
It can thus be seen that (for fixed values of other substitution parameters) the proportion of doublet mutations is a strictly increasing, sigmoidal, function of $d$.
In the case of $d = 0$ and $\pi_{xy} = \pi_x \pi_y$, the model collapses to a standard GTR+G model.

\subsection*{Simulation\label{sec:simulation}}

\subsubsection*{Simulation grid\label{sec:leviathan}}
With the epistatic doublet model, there are two variables that govern the capacity for epistasis to affect phylogenetic inference: the strength of the interactions, and the proportion of the alignment that is epistatic.
To investigate the effect of the strength of epistasis, we simulate with $d = \{0.0,0.5,2.0,8.0,1000.0\}$, which encompasses both realistic (see below) and extreme values.
Simulating $d=0$ allows us to disentangle the effect of model misspecification due to the doublet stationary frequencies from model misspecification due to paired substitutions.
Our values of $d$ correspond to 0\%, 3.2\%, 11.6\%, 34.5\%, and 98.5\% of all substitutions at a pair of sites being doublet substitutions.
To understand the effect of adding epistatic sites, for each value of $d$ we simulate a grid where we independently vary the number of epistatic sites, $n_e$ and independent sites, $n_i$.
This setup is more informative than one in which we hold the number of sites constant and vary the proportion of sites coming from the epistatic model.
It allows us to examine whether a posterior predictive test is capable of detecting the presence of only a few epistatically paired sites or whether it requires a larger number.
By comparing the accuracy of inference on a dataset with $n$ sites (possibly a mixture of independent and epistatic sites) to one with $n + n_e$ sites, we can determine if we are in the catastrophic model misspecification regime (inference with $n + n_e$ sites is worse than with $n$ sites) or the best-case regime (inference with $n + n_e$ is better than with $n$ sites).
\skhcomment{I like the idea of being very clear here what the possible outcomes are. Andy mentioned in slack that we want to be clear that we think epi sites are less useful but not misleading.}

For each value of $d$, we simulate a grid with $n_i,n_e \in \{0, 16, 32, \dots, 400\}$, excluding the cell in which $n_i = n_e = 0$.
To keep computation costs down, at each grid point we simulate a single alignment, and we refer to these alignments collectively as the ``real'' alignments.
While this setup does not afford us a precise estimate of any quantity at any grid cell, this is not an issue.
For our statistical analyses, including estimation of the value of an epistatic site, the presence of sampling noise is expected by the models.

\subsubsection*{Simulating parameters\label{sec:tunicates}}
To ensure that our simulation regime is realistic, we targeted our simulating parameters on values inferred from the dataset of \cite{tsagkogeorga2009updated}.
As we are primarily interested in the epistatic model parameters, we first inferred a fixed tree using RAxML \citep{stamatakis2014raxml}.
Fixing this tree, we then used RevBayes \cite{hohna2016revbayes} to infer the epistatic doublet model parameters.
The inferred value of $d$ for this dataset is approximately 0.65.
On a dataset that spans eukaryotes, \citet{nasrallah2013phylogenetic} inferred values as high as 7.59 in fixed-tree analyses and 9.72 when inferring the tree.
Thus, our simulating values of $d$ include both extreme values, $d=\{0,1000\}$, and biologically relevant values, $d = \{0.5,2.0,8.0\}$ as biologically relevant values.
We use the RAxML tree for simulation, and all other parameters are fixed to the posterior mean values from the RevBayes analysis.
Simulating values of all parameters are available in Supplementary Table \ref{}.

\subsubsection*{Bayesian inference\label{sec:mcmc}}
We use RevBayes \citep{hohna2016revbayes} to infer unrooted phylogenies for each of the ``real'' alignments.
In all cases, we use a single GTR+G substitution model, intentionally ignoring the presence of epistasis in the datasets.
Details of the model setup, priors, and MCMC moves used are available in the supplement.
For each analysis we run two independent MCMC chains.
In order to avoid analysis artifacts due to convergence issues we perform convergence diagnostics and exclude all grid cells that fail from downstream analysis.
As we are interested in the phylogeny specifically, our convergence diagnostics focus on the tree and branch lengths.
First, we use the average standard deviation of split frequencies (ASDSF) to compare topologies between the two chains.
To account for the possibility of branch-length convergence issues, we also check if the tree length distributions between chains by using the potential scale reduction factor \citep[PSRF,\ ][]{brooks1998general}.
However, we must balance the stringency of our convergence standards against the number of analyses that must be discarded.
To this end, we discard all chains where either ASDSF $>$ 0.05 or PSRF $>$ 1.1, and in the supplement we present additional results using different standards to assess the sensitivity of our results to the convergence standards.


\subsection*{Posterior predictive assessments\label{sec:pps}}

The posterior-predictive distribution is the distribution on new (replicate) datasets, $y^{\text{rep}}$, that we could draw from our posterior distribution, $p(\theta \mid y)$.
It is obtained by integrating the probability of a new dataset given a particular value of the model parameters $p(y^{\text{rep}} \mid y, \theta)$, across the posterior,
\[
  p(y^{\text{rep}} \mid y) =
  \int p(y^{\text{rep}} \mid y, \theta)\,
  p(\theta \mid y)\,
  \text{d}\theta.
\]
Often we are more interested in a particular feature of a dataset, given by a test statistic $T(y)$.
The posterior predictive distribution for this test statistic is given by,
\[
  p(T(y^{\text{rep}}) \mid y) =
  \int p(T(y^{\text{rep}}) \mid y, \theta)\,
  p(\theta \mid y)\,
  \text{d}\theta.
\]
We can use the posterior predictive distribution of a test statistic to determine if our model is adequate, or in other words if it fits the data in the absolute sense.
If the model is adequate, than the observed value of the test statistic on the real data, $T(y)$, should be near the center of mass of the posterior predictive distribution and not out in the tails.
We can thus compute a posterior predictive p-value, $\text{Pr}(T(y^{\text{rep}}) \geq T(y))$, and if the posterior-predictive p-value is smaller than some threshold $\alpha$, we declare the model to be inadequate.
In practice, one obtains a Monte Carlo estimate of the posterior predictive p-value by simulating new datasets using the draws from the posterior obtained by MCMC, computing the test statistic for each, and calculating the proportion greater than or equal to the observed value.
For a more complete introduction to posterior predictive model checks see \citet{gelman2004bda}, or for a review of model adequacy in evolutionary biology see \citet{brown2018evaluating}.

One of our key questions is, can the presence of unmodeled epistatic interactions be detected with posterior predictive checks?
A test statistic should be chosen on the basis of its ability to detect a particular form of model variation.
As epistasis has yet to be studied from a posterior predictive perspective, there are currently no test posterior predictive approaches designed explicitly to detect it.
We first examine whether a standard phylogenetic posterior predictive test-statistic, the multinomial likelihood test statistic of \cite{goldman1993statistical} can detect this model misspecification.
We then develop two new statistics based on information theory that directly address the expected behavior of epistasis.

We will examine the performance of these test statistics on simulated datasets in two ways.
First, by using only the simulated ``real'' alignments, we will examine if these test statistics are sensitive in principle to the presence of epistasis and to the proportion of epistatic sites in the alignment.
A test statistic that is sensitive in principle to epistatic interactions among sites should vary with the proportion of epistatic sites in an alignment and/or with $d$.
Then we will perform posterior predictive checks for all inferred phylogenies to determine if the statistics are able to detect epistasis in practice.
As an example of this distinction, consider that in principle the GY statistic is capable of detecting the difference between certain GTR \citep{tavare1986some} models and certain HKY \citep{hasegawa1985dating} models.
However, if we simulate an alignment under HKY and infer it under GTR, we will not see any evidence of misspecification \citep{bollback2002bayesian}, so in practice it cannot detect all forms of misspecification.

\subsubsection*{Multinomial likelihood\label{sec:goldman}}

The multinomial likelihood test statistic treats the multiple sequence alignment $\boldsymbol{D}$ as a draw from a multinomial distribution on all possible site patterns.
For $t$ taxa and a DNA or RNA alignment, there are $4^t$ such patterns, and for an alignment of length $n$ we observe some number $s \leq n$ site patterns.
If $s_i$ is the number of times we see site pattern $i$, the maximum likelihood estimate of the multinomial probability of seeing pattern $i$ is $p(i) = s_i / n$.
The test statistic is simply the log-likelihood of this dataset using these estimated probabilities, or $\mathcal{L} = \sum_i [ s_i \log(s_i)]  - n \log(n)$.

\subsubsection*{Mutual information\label{sec:mi}}

Under a phylogenetic model, all sites are conditionally independent given the phylogeny.
However, under the epistatic doublet model, epistatic pairs of sites evolve dependently along the phylogeny due to both $d$ and the use of doublet stationary frequencies.
In particular, the presence doublet substitutions make it more likely that when one site in a pair changes along a branch, the other site does as well.
This should result in pairs of epistatic sites having more similar patterns than independent sites, and the degree of this similarity should depend on $d$.
What is needed, then, is a way to capture this idea of the similarity of sites.

Mutual information is a measure of the dependency of two variables, quantifying the amount of information that one contains about the other.
The higher the mutual information, the more that knowing the value of one variable tells you about the other, in other words the more similar the two variables are.
As above, we assume that we have an $t$ taxa by $n$ sites multiple sequence alignment $\boldsymbol{D}$, and here we denote the alphabet of this alignment $\mathcal{A}$.
For an RNA alignment, $\mathcal{A} = (A,C,G,U)$, for a DNA alignment, $\mathcal{A} = (A,C,G,T)$.
The mutual information of a pair of sites $(i,j)$ is given by,
\[
I_{ij} = \sum_{(a,b)\in\mathcal{A}^2}f_{ij}(a,b)\log\left(\frac{f_{ij}(a,b)}{f_i(a)f_j(b)}\right),
\]
where $f_i(a)$ is the relative frequency of character $a$ at site $i$,
\[
f_i(a) = \frac{1}{t}\sum_{k=1}^{t}\mathbbm{1}_{\{D_{ki}\}}(a),
\]
and $f_{ij}(a,b)$ is the relative joint frequency of character $a$ at site $i$ and character $b$ at site $j$,
\[
f_{ij}(a,b) = \frac{1}{t}\sum_{k=1}^{t}\mathbbm{1}_{\{D_{ki}\}}(a) \mathbbm{1}_{\{D_{kj}\}}(b).
\]

If we had an \textit{a priori} hypothesis about a pair of interacting sites $(i,j)$, we could thus compute the posterior predictive distribution of $I_{ij}$ and compare the observed value to this distribution.
However, if one wants to test for the presence or absence at the level of the entire alignment, this will not work.
However, for an alignment we can compute the mutual information of all pairs of sites, $\boldsymbol{I}$.
As we expect epistasis to increase the mutual information between pairs of interacting sites, the upper tail of $\boldsymbol{I}$ should be informative with respect to the overall presence and strength of epistasis.
We consider two summaries of $\boldsymbol{I}$.
First we consider the skew of $\boldsymbol{I}$, $I_s$, which should be sensitive to the strength of epistasis and proportion of epistatic sites, as the more interactions the more values that should fall in the right tail and the stronger the interactions the larger those values should get.
We also consider the max, $I_m$, which should be sensitive to the presence or absence of epistasis, but is less likely to be sensistive to the proportion of epistatic sites.

\subsection*{Effective sequence length}

\citet{nasrallah2011quantifying} define the effective sequence length, $n_{eff}$ to be the length of a hypothetical alignment drawn from a site-independent model which yields the same phylogenetic accuracy as the dependent alignment.
An alternative to this is to define $n_{eff}$ in terms of the phylogenetic precision instead of accuracy.
In any model-misspecification regime, we would expect that $n_{eff} < n$, that is, we expect the effective sequence length to be less than the true sequence length.
In our simulations, $n = n_i + n_e$, which allows us to quantify which misspecification scenario applies.
In the best-case scenario, $n_i \leq n_{eff} \leq n_i + n_e$, while in the catastrophic misspecification scenario $n_{eff} < n_i$.
In order to quantify the effective sequence length, then, we need to first define measures of accuracy and precision, then we can choose an approach to estimate the effective sequence length.

% Both of these definitions contrast with the classical definition of effective sample size


\subsubsection*{Accuracy\label{sec:error}}
As we are interested in Bayesian inference, we are not primarily interested in the accuracy in point estimates of the phylogeny but in the overall goodness of the posterior distribution of trees.
We employ two tree distance metrics, the Robinson-Foulds (RF) distance \citep{robinson1981comparison} and the branch score or Kuhner-Felsenstein (KF) distance \citep{kuhner1994simulation}.
RF distance is a purely topological measure between a pair of trees, capturing the number of splits (bipartitions of taxa) present in one tree but not in the other.
The KF distance is the sum of squared differences in branch lengths between trees, treating a missing split in either tree as a 0, and so captures differences in both topology and branch length.
The quantity that we are interested in is thus the posterior distribution on distances to the true tree.
Given that we have samples from our posterior distribution on phylogenies, we can obtain samples from the posterior distribution on tree distances.
We consider multiple univariate summaries of this distribution, namely the mean, median, minimum, and maximum of the distances, as well as the 2.5, 5, 95, and 97.5 percentiles.

While comparisons based on the entire posterior distribution are useful for understanding the overall performance of inference, they do not necessarily reflect the experience of practitioners inferring phylogenies.
In practice, the posterior distribution is, at least for the purposes of visualization, generally reduced to a single summary tree, often a majoriy rule consensus (MRC) tree.
Thus, as an alternative accuracy measure, we take the number of splits in the MRC tree that are not in the true tree as an error measure of the point tree estimate.

\subsubsection*{Precision\label{sec:precision}}
To investigate precision-based effective sequence lengths, we must define a measure of the precision or variance of our posterior distributions.
In the best-case scenario, where epistasic sites are simply less informative than independent sites, one would intuitively expect that the variance of the posterior distribution on trees should increase.
On the other hand, in the catastrophic scenario, it is possible that the increase in information about certain edges in the tree, the variance of the posterior distribution may actually decrease.
While the variance of a phylogeny is defined \citep[e.g.\ ][]{willis2019confidence}, the time required to compute this variance makes it prohibitively expensive for our purposes \citep{brown2019mean}.
In order to address the matter of variance, we thus turn to two surrogates.

The first metric we consider is the resolution of the majority-rule consensus (MRC) tree \citep{}.
The MRC tree is obtained by including all splits in the posterior that occur with a frequency above 50\%.
As the amount of information in an alignment increases, there should be more splits with sufficient signal to place in the MRC tree and the MRC tree should include more splits.
An MRC tree on $t$ taxa includes a maximum of $2 t - 3$ non-trivial splits, so dividing the number of (non-trivial) splits in the MRC tree by $2 t - 3$ produces a standardized value in [0,1] which we call the proportion of resolved splits.
At 0, the MRC tree is completely unresolved (a star tree), while at 1 it is a fully resolved tree.
While this metric takes a somewhat circuitous path to precision, the focus on the summary tree ties it more closely to tangible effects of variance encountered when reading a paper that estimates a phylogeny.

As an alternate metric, we consider the width of the 95\% CI of the distances to the true tree.
The more information there is in an alignment, the narrower we expect the posterior distribution on trees, and thus the narrower we expect the distribution on distances to the true tree.
We focus here on the KF distance as it is a purely topological measure and does not include any potentially confounding effects due to erroneously long (or short) estimated trees.
This metric has the downside of being linked to the accuracy of the inference, which is less than ideal, but like our other metric it is correlated with the true precision of the distribution, and it has the benefit of requiring no extra computations, somewhat reducing the otherwise heavy CO$_2$ cost of this paper.

\subsubsection*{Computing the effective sequence length\label{isotonic_regression}}
\amcomment{This section is a bit rough, it is going to need some work. I'm not sure if we want or need the bit about the effective sample size. It wasn't until I took a look at that that I realized how different it is from what we're doing and that I figured out how to frame what we're doing. So we may well be able to get away with a shorter section there.}

The effective sequence length is a hypothetical comparison: how many independent sites is this alignment worth.
We have explored accuracy- and precision-based measures that may allow us to define worth, but to actually compute the effective sequence length we must adopt a mathematical definition.
Let $S(n)$ be the value of some summary of an inference on a dataset with $n$ sites drawn from some arbitrary model.
This definition is intentionally vague on both the model the sites are drawn from and the summary.
The sites could be drawn from a site-independent model, or a model that introduces dependency among sites, such as the Nasrallah-Huelsenbeck model of pairwise epistasis.
As examples $S(n)$ could include the distance between a maximum likelihood tree and the true tree, or the variance of the posterior distribution of trees.
If $S(n)$ is a summary of accuracy, then this definition includes that of \citet{nasrallah2011quantifying}.
The effective sequence length is $n_{eff}$ such that $E[S(n)] = E[S(n_{eff})]$.
That is, if we repeatedly draw datasets with $n$ sites from some arbitrary, possibly pairwise dependent, model and $n_{eff}$ from the (site-independent) model used for analysis, then $n_{eff}$ is the number of indepedent sites such that the average summary value is the same as for the $n$ sites from the arbitrary, possibly misspecified, model.
Note that we can ignore the number of taxa because it must be the same between the datasets.
It is also worth noting that this formulation of an effective sequence length is broader than the formulation of the effective sample size.
Classically, the notion of effective sample size, $n^*$ is defined with respect to the variance of an estimator $\hat{\theta}$.
Specifically, the effective sample size is $n^*$ such that $Var(\hat{\theta} \mid n) = Var(\hat{\theta} \mid n^*)$.
The variance of an estimator is given by $Var(\hat{\theta}) = E[ (\hat{\theta} - E[\hat{\theta}])^2 ]$.
Thus, if we take $S(n) = (\hat{\theta} - E[\hat{\theta}])^2$, then we can see that our definition includes the standard definition of effective sample size.

In our case, with $n = n_i + n_e$, we can define a model for the effective sequence length as $n_{eff} = n_i + r(d) \times n_e$ where $r(d)$ is the relative worth of an epistatic site compared to an independent one for a given value of $d$.
The dependency on $d$ is necessary because we expect that as $d$ increases and more substitutions are paired, the relative worth should decrease.
It is possible that $r$ is also not a constant; if there is asymptotic bias and the estimated tree does not converge to the true tree, then $r$ must eventually go to 0.
However, in our finite data regime there is no evidence of asymptotic biases, and a model with constant $r$ will suffice.
Estimating $r$ is complicated by the fact that we do not know an appropriate functional form for $E[S(n_{eff})]$ for any of our metrics.
We know that accuracy and precision should both increase with increasing $n_{eff}$, but how rapidly this happens is unknown.
Thus, to infer $r$ we turn to models where we do not need to explicitly specify this relationship.
Specifically, we use isotonic regression to model the relationship between $S(n_{eff})$ and $n_{eff}$, and we fit our model with least squares.
Isotonic regression, as implemented in the \texttt{isoreg} function in the R package \texttt{stats} \citep{R}, fits a piecewise constant function for $E[S(n_{eff})]$.

\subsection*{Data and code availability\label{sec:its_on_github}}
All the code you need to reproduce these analyses is available somewhere.
But not all the files we produced because that's a loooot of logfiles and a loooot of space required, sorry.


\section*{Results\label{sec:results}}

\amcomment{All values reported are currently over the entire simulation grid, no filtering has been performed for MCMC runs that fail convergence diagnostics.}

\subsection*{Posterior predictive tests\label{pps_results}}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{figures/test_stat_sensitivity.pdf}
  \caption{
  The values of all three test statistics plotted against the proportion of sites in the alignment drawn from the epistatic model, colored by $d$.
  Values are for the grid of ``real'' alignments corresponding to part (b) of Figure \ref{fig:schematic}
  All statistics show at least a degree of sensitivity to the proportion of epistatic sites, and some sensitivity to $d$.
  The plot is restricted to simulations where $384 \leq n_i + n_e \leq 416$ to remove the effect of the number of sites on the GY93 statistic.
  }
  \label{fig:test_stat_sensitivity}
\end{figure}

All three test statistics examined exhibit sensitivity to the presence of epistatic interactions and to the value of $d$ (Figure \ref{fig:test_stat_sensitivity}) in our ``real'' alignments (Figure \ref{fig:schematic}).
Thus, in principle all three statistics are capable of detecting epistasis in alignments.
Of the three statistics, $MI_{max}$ shows the most consistent separation by $d$, with a steady increase in average as $d$ increases, where both $MI_{kurt}$ and $GY93$ show large leaps in average values between $d=8$ and $d=1000$.
Similarly, for both the $GY93$ and $MI_{kurt}$ statistics there is a clear difference in their relationship to the proportion of epistatic sites between $d = 8$ and $d = 1000$, while the $MI_{max}$ statistic has a more consistent relationship across $d$.
The $GY93$ statistic is by far the most sensitive to the total number of sites in the alignment, with a correlation coefficient of -0.99 between $GY93$ and $n_i + n_e$ where the correlation coefficients for $MI_{kurt}$ and $MI_{max}$ were 0.19 and 0.28 respectively.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{figures/power_curves.pdf}
  \caption{
  Power to detect epistasis using posterior predictive checks at $\alpha = 0.05$.
  Power is the proportion tests yielding a statistically significant result, that is, the true positive rate.
  Curves are averages over windows of 10\% windows of the proportion of epistatic sites.
  }
  \label{fig:power_curves}
\end{figure}

In practice, both information theoretic summary statistics outperform $GY93$, with $MI_{max}$ performing the best.
We test the practical properties of our statistics by performing posterior predictive simulation for each ``real'' alignment (Figure \ref{fig:schematic}).
An ideal test statistic has a high power (true positive rate) and a false positive rate equal to the specified $\alpha$, which we take to be 0.05.
The $MI_{max}$ statistic has a false positive rate of 0.059, averaged over all simulations with no epistasis present (that is, with $d = 0$ or $n_e = 0$), and as can be seen in Figure \ref{fig:power_curves}, and reaches a maximum power of 1 at both $d = 8$ and $d = 1000$.
The $MI_{kurt}$ statistic has a false positive rate of 0.0026, with a maximum power at $d = 1000$ of 0.92.
The $GY93$ statistic has a false positive rate of 0, and achieves a maximum power of 0.51 at $d = 1000$.
Averaged over all proportions of epistatic sites, the $MI_{max}$ statistic has a power of 0.17 at $d = 0.5$, comparable to the power of the $GY93$ statistic at $d = 1000$ (0.18), and a power of 0.55 at $d = 2$, comparable to the power of the $MI_{kurt}$ statistic at $d = 1000$ (0.56).
We assess the sensitivity of these results to the strictness of MCMC convergence diagnostics, and find that there is little difference between the results presented here, and those based on either strict or no convergence filtering (Figure some figure in supplement).

\subsection*{Worth of an epistatic site}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{figures/relative_worth.pdf}
  \caption{
    Bootstrapped estimates of $r(d)$ for our simulated values of $d$.
    Inference was performed via least squares using isotonic regression.
    Accuracy-based estimates use the average posterior RF distance to the true tree, while precision-based estimates use the proportion of resolved splits in the MRC tree.
    The boxplots summarize 1000 bootstrap replicates.
  }
  \label{fig:worth}
\end{figure}

To infer the effectice sequence length, we employ isotonic regression.
In this setup, we have $E[S(n)] = f(n_i + r(d) \times n_e)$, where $S(n)$ is a summary of inference and $f()$ is a piecewise-constant function.
For our summary measures, we focus on one accuracy-based measure, the average posterior RF distance to the true tree, and one precision-based measure, the percent of resolved splits in the MRC tree.
Alternate results using different measures will eventually make their way into the supplementary materials.
In order to quantify the uncertainty in our estimates of $r(d)$, we use nonparametric bootstrapping \citep{efron1992bootstrap} and infer the model on 1000 bootstrap replicate datasets for each summary measure and each value of $d$.
As with the power analyses, we also assess the sensitivity of our inference of the worth of a site to the MCMC convergence standards employed.
We find that the overall patterns remain qualitatively unchanged regardless of convergence cutoff (Figure something in the supplement).

In all cases, we infer that $0 < r(d) < 1$, meaning that the model misspecification here falls into the best-case scenario rather than the catastrophic one (Figure \ref{fig:worth}).
For our accuracy-based estimates, we infer $r(1000) < r(8) < r(2) < r(0.5)$, meaning that increasing the strength of epistatic interactions decreases the value of a site.
For the precision-based estimates using the resolution of the MRC tree we see the same general trend, though it is unclear whether $r(8) < r(2)$, but this could simply be noise.
Additionally, in all cases $r(0) < 1$, meaning that there is an overall cost to inference due to the misspecified base frequencies, beyond simply the cost of doublet substitutions.
Oddly, for our accuracy-based modeling, we find that $r(0) > r(0.5)$ (other summary approaches bear this phenomenon out).
Perhaps most noteworthy though is the fact that for all values of $d$, we find that $r_{accuracy}(d) < r_{precision}(d)$.
This means that inference is somewhat more precise than it ``should be,'' because the accuracy added by adding an epistatic site is less than the precision added.
To give a concrete example, for $d = 0.5$, $r_{accuracy}(0.5) = 0.783$ while $r_{precision}(0.5) = 0.853$, so if one added 50 pairs of dependent sites (100 sites total) to an alignment, accuracy would increase as if 78.3 sites had been added, but precision would increase as if 85.3 sites had been added, a discrepancy of 7 sites.

\section*{Discussion\label{sec:discussion}}

We set out to understand the role of epistasis in phylogenetic inference.
Focusing in on pairwise epistasis in the form of RNA doublet models, we asked two questions.
Can we detect epistasis in alignments with posterior predictive checks?
What is the effect of pairwise epistasis on the quality of phylogenetic inference.
Overall, we find that the right test statistic can detect epistasis with good power and few false positives, and that (pairwise) epistasis is only mildly harmful to phylogenetic inference.

In our simulations, the model we used for inference was misspecified due to both differences in the relative exchange rates and in the stationary frequencies.
Our inference model is a standard GTR+G model which works on individual sites, while our simulated data includes a mix of sites drawn from a site-iid GTR model and an epistatic doublet model.
The doublet model is inherently a model of site pairs, both because it uses doublet stationary frequencies and because $d$ allows for substitutions at both sites.
However, the doublet model still produces a pattern of substitutions at individual sites, so we can decompose the model misspecification into two parts: the portion due to paired substitutions, and the portion due to the fact that there are essentially two different site-level GTR models.
The misspecification due to paired substitutions is a strictly increasing function of $d$.
The misspecification due to the difference in underlying GTR models (the real one underyling the independent sites, and the hypothetical one underlying the epistatic sites) is somewhat less transparent.
However, it appears that the difference is greatest between these two at $d = 0$, much less at $d = 0.5$, and then increases with $d$.
This pattern could explain our observation that the worth of an epistatic site at $d = 0$ is less than for $d = 0.5$.

Our posterior predictive checks for epistasis show that pairwise epistasis can be detected with the appropriate summary statistics.
While the standard multinomial likelihood statistic has some ability to detect epistasis at the extreme of $d = 1000$ (an average power across all simulations of 0.18), it cannot detect realistic strengths of epistasis, and so it is not a particularly useful statistic.
We also introduced two statistics based on mutual information.
In both cases, we compute all the mutual information for all site pairs in the alignment, our statistics simply differ in how they summarize this distribution.
One summary we considered is the kurtosis of this distribution, which has decent power at $d = 1000$ (power of 0.56), but at $d = 8$ power is much lower (0.07) and it has little ability to detect weaker epistasis.
Our second summary, the maximum of the pairwise mutual information values, was much more successful.
Averaging over all simulations, power is 0.17 at $d = 0.5$, 0.55 at $d = 2$, and 0.9 at $d = 8$, and despite this power the false positive rate is not exagerated ($\alpha = 0.05$, false positive rate = 0.06, though the distribution of p-values does not appear to be quite uniform under the null hypothesis).
It is possible that summary statistics that take better advantage over the extreme upper end of the distribution of pairwise mutual information would have even better power, but we leave this to future research.
It is also possible that one could identify interacting pairs of sites using the maximum mutual information, and then test if these pairs are significantly interacting using the posterior predictive distribution of mutual information for that pair of sites.

We defined two scenarios for the worth of an epistatic site.
In the catastrophic scenario, epistatic sites are worth some negative number of sites, such that adding epistatically interacting sites to an alignment of independent sites will make inference worse.
In the best-case scenario, epistatic sites contribute positively to inference, but not as much as independent sites.
Our simulations show conclusively that the sort of epistasis modeled by \citet{nasrallah2013phylogenetic} falls into the best-case scenario.
When epistasis is simulated near maximum strength, we estimate that epistatic sites are worth slightly 40\% to 50\% of independent sites, while more realistic strengths lead to worths of 60\% to 80\%.
One slight caveat is that epistasis has slightly different effects on the accuracy and precision of inference.
When we define the worth of a site in terms of the increase in precision, we get slightly higher estimates of worth.
This means that in practice when epistasis is present in phylogenetic datasets, inference will be slightly overconfident.
Still, this effect is relatively mild for realistic values of the strength of epistasis, and it does not undermine the simple fact that adding epistatically paired sites improves inference.

Overall, our results are quite promising for phylogenetic inference in the face of unmodeled epistasis.
While epistasis decreases the accuracy and precision of inference, it does so slightly and not catastrophically.
The addition of epistatic site pairs to an aligment will still lead to overall better inference, simply not inference as good as adding an equal number of independent sites from the true model.
And moreover, when there is pairwise epistasis in an alignment we have shown that it can reliably be detected with a new test statistic: the maximum pairwise mutual information of sites.
Thus, if one is worried that pairwise epistasis is interfering with their estimates, they can now detect it with good power and a low risk of false positives.
Further work will need to be done using other models of epistasis (pairwise and higher order) to check that our findings on the effect of epistasis are not simply localized to one region of the space of epistatic models.
It is likely that our new test statistic will also be useful for detecting other forms of pairwise epistasis, though this should also be tested.
Our results suggest that in practice, phylogenies inferred from alignments with pairwise epistasis are still reliable estimates.

\section*{Supplementary Material}

\section*{Sensitity to MCMC convergence}
All analyses presented in the paper filter out simulations for which MCMC convergence failed.
We define failure to be PSRF $> 1.1$ or ASDSF $> 0.05$, a threshold that reflects our desire to balance convergence standards against retaining sufficient simulation replicates to make inferences from.
To determine whether our results are robust to the convergence criterion, we now present results for Figures \ref{fig:power_curves} and \ref{fig:worth} in which we consider using all the data regardless of MCMC convergence diagnostics (``no convergence''), the standards presented in the main text (``convergence'') and a stricter standard (PSRF $> 1.01$ or ASDSF $> 0.01$, ``strict convergence'').
As can be seen in Figure \ref{fig:power_curves_sensitivity}, the inferred power to detect epistasis is unaffected by convergence standards.
Similarly, Figure \ref{fig:worth_sensitivity}, the inferred worth of epistatic sites is qualitatively unaffected by convergence cutoffs.
The inferred worth values are also similar with the exception of the precision-based worth using strict standards.
For $d = 1000$, the worth inferred from precision is higher than for the other convergence standards.
However, the stricter convergence standards resulted in discarding over 33\% of the simulations at $d = 1000$, while for the other $d$ values less than 25\% were discarded, so the discrepency is likely a result of losing data.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{figures/power_curves_sensitivity.pdf}
  \caption{
  Power to detect epistasis using posterior predictive checks at $\alpha = 0.05$ across three different convergence thresholds.
  The lowest threshold is to simply include all simulations (``no convergence''), the intermediate threshold is to remove any runs with PSRF $> 1.1$ or ASDSF $> 0.05$ (``convergence''), and the strict threshold is to remove any runs with PSRF $> 1.01$ or ASDSF $> 0.01$ (``strict convergence'').
  Power is the proportion tests yielding a statistically significant result, that is, the true positive rate.
  Curves are averages over windows of 10\% windows of the proportion of epistatic sites.
  }
  \label{fig:power_curves_sensitivity}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{figures/relative_worth_sensitivity.pdf}
  \caption{
    Bootstrapped estimates of $r(d)$ for our simulated values of $d$ across three different convergence diagnostic thresholds.
    The lowest threshold is to simply include all simulations (``no convergence''), the intermediate threshold is to remove any runs with PSRF $> 1.1$ or ASDSF $> 0.05$ (``convergence''), and the strict threshold is to remove any runs with PSRF $> 1.01$ or ASDSF $> 0.01$ (``strict convergence'').
    Inference of worth was performed via least squares using isotonic regression.
    Accuracy-based estimates use the average posterior RF distance to the true tree, while precision-based estimates use the proportion of resolved splits in the MRC tree.
    The boxplots summarize 1000 bootstrap replicates.
  }
  \label{fig:worth_sensitivity}
\end{figure}
\section*{Acknowledgments}
We thank our PIs for giving us the freedom to pursue this project and the gods for not striking us down for our unholy combination of python, R, and Rev scripting.

\bibliographystyle{plainnat}
\bibliography{refs}






\end{document}
